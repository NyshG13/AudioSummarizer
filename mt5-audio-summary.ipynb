{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12302259,"sourceType":"datasetVersion","datasetId":7754166},{"sourceId":12302404,"sourceType":"datasetVersion","datasetId":7754269}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q demucs\n!pip install -q transformers torchaudio librosa accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:34:08.415988Z","iopub.execute_input":"2025-07-01T18:34:08.416214Z","iopub.status.idle":"2025-07-01T18:35:35.987253Z","shell.execute_reply.started":"2025-07-01T18:34:08.416186Z","shell.execute_reply":"2025-07-01T18:35:35.986288Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from demucs.apply import apply_model\nfrom demucs.pretrained import get_model\nfrom demucs.audio import AudioFile\nimport torchaudio\nimport torch\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:01.974411Z","iopub.execute_input":"2025-07-01T18:36:01.975151Z","iopub.status.idle":"2025-07-01T18:36:06.260464Z","shell.execute_reply.started":"2025-07-01T18:36:01.975113Z","shell.execute_reply":"2025-07-01T18:36:06.259687Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Noise reduction model","metadata":{}},{"cell_type":"code","source":"model = get_model(name='htdemucs')\n# model.cpu()\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:34.009364Z","iopub.execute_input":"2025-07-01T18:36:34.009745Z","iopub.status.idle":"2025-07-01T18:36:35.273740Z","shell.execute_reply.started":"2025-07-01T18:36:34.009722Z","shell.execute_reply":"2025-07-01T18:36:35.272939Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /root/.cache/torch/hub/checkpoints/955717e8-8726e21a.th\n100%|██████████| 80.2M/80.2M [00:00<00:00, 176MB/s] \n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"BagOfModels(\n  (models): ModuleList(\n    (0): HTDemucs(\n      (encoder): ModuleList(\n        (0): HEncLayer(\n          (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n          (norm1): Identity()\n          (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (1): HEncLayer(\n          (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n          (norm1): Identity()\n          (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (2): HEncLayer(\n          (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n          (norm1): Identity()\n          (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (3): HEncLayer(\n          (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n          (norm1): Identity()\n          (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n      )\n      (decoder): ModuleList(\n        (0): HDecLayer(\n          (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n          (norm2): Identity()\n          (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (1): HDecLayer(\n          (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n          (norm2): Identity()\n          (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (2): HDecLayer(\n          (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n          (norm2): Identity()\n          (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (3): HDecLayer(\n          (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n          (norm2): Identity()\n          (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n      )\n      (tencoder): ModuleList(\n        (0): HEncLayer(\n          (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n          (norm1): Identity()\n          (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (1): HEncLayer(\n          (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n          (norm1): Identity()\n          (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (2): HEncLayer(\n          (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n          (norm1): Identity()\n          (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (3): HEncLayer(\n          (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n          (norm1): Identity()\n          (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n          (norm2): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n      )\n      (tdecoder): ModuleList(\n        (0): HDecLayer(\n          (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n          (norm2): Identity()\n          (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (1): HDecLayer(\n          (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n          (norm2): Identity()\n          (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (2): HDecLayer(\n          (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n          (norm2): Identity()\n          (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n        (3): HDecLayer(\n          (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n          (norm2): Identity()\n          (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n          (norm1): Identity()\n          (dconv): DConv(\n            (layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n              (1): Sequential(\n                (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n                (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n                (2): GELU(approximate='none')\n                (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n                (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n                (5): GLU(dim=1)\n                (6): LayerScale()\n              )\n            )\n          )\n        )\n      )\n      (freq_emb): ScaledEmbedding(\n        (embedding): Embedding(512, 48)\n      )\n      (channel_upsampler): Conv1d(384, 512, kernel_size=(1,), stride=(1,))\n      (channel_downsampler): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n      (channel_upsampler_t): Conv1d(384, 512, kernel_size=(1,), stride=(1,))\n      (channel_downsampler_t): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n      (crosstransformer): CrossTransformerEncoder(\n        (norm_in): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm_in_t): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (layers): ModuleList(\n          (0): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n          (1): CrossTransformerEncoderLayer(\n            (cross_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n          )\n          (2): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n          (3): CrossTransformerEncoderLayer(\n            (cross_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n          )\n          (4): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n        )\n        (layers_t): ModuleList(\n          (0): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n          (1): CrossTransformerEncoderLayer(\n            (cross_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n          )\n          (2): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n          (3): CrossTransformerEncoderLayer(\n            (cross_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n          )\n          (4): MyTransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n            )\n            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n            (dropout): Dropout(p=0.02, inplace=False)\n            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.02, inplace=False)\n            (dropout2): Dropout(p=0.02, inplace=False)\n            (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n            (gamma_1): LayerScale()\n            (gamma_2): LayerScale()\n          )\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"input_audio_path = \"/kaggle/input/whisper-test-5/audio test timeless.unknown\"\noutput_dir = \"/kaggle/working/denoised\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:48.525274Z","iopub.execute_input":"2025-07-01T18:36:48.525972Z","iopub.status.idle":"2025-07-01T18:36:48.530320Z","shell.execute_reply.started":"2025-07-01T18:36:48.525937Z","shell.execute_reply":"2025-07-01T18:36:48.529554Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"source = AudioFile(input_audio_path)\nref = source.read(streams=0, channels=1)\nwav = ref[0]\nsample_rate = source.samplerate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:50.360836Z","iopub.execute_input":"2025-07-01T18:36:50.361427Z","iopub.status.idle":"2025-07-01T18:36:51.022291Z","shell.execute_reply.started":"2025-07-01T18:36:50.361404Z","shell.execute_reply":"2025-07-01T18:36:51.021505Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Step 1: Ensure wav is a tensor with shape (1, T)\nif not isinstance(wav, torch.Tensor):\n    wav = torch.tensor(wav)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:52.352616Z","iopub.execute_input":"2025-07-01T18:36:52.352867Z","iopub.status.idle":"2025-07-01T18:36:52.356470Z","shell.execute_reply.started":"2025-07-01T18:36:52.352847Z","shell.execute_reply":"2025-07-01T18:36:52.355923Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"if wav.ndim == 1:\n    wav = wav.unsqueeze(0)\nprint(wav.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:53.647124Z","iopub.execute_input":"2025-07-01T18:36:53.647573Z","iopub.status.idle":"2025-07-01T18:36:53.652287Z","shell.execute_reply.started":"2025-07-01T18:36:53.647542Z","shell.execute_reply":"2025-07-01T18:36:53.651487Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 10129408])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"if wav.shape[0] == 1:\n    wav = torch.cat([wav, wav], dim=0)\nprint(wav.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:54.978416Z","iopub.execute_input":"2025-07-01T18:36:54.979073Z","iopub.status.idle":"2025-07-01T18:36:55.015915Z","shell.execute_reply.started":"2025-07-01T18:36:54.979050Z","shell.execute_reply":"2025-07-01T18:36:55.015179Z"}},"outputs":[{"name":"stdout","text":"torch.Size([2, 10129408])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"wav = wav.unsqueeze(0).float()\nprint(wav.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:36:59.712572Z","iopub.execute_input":"2025-07-01T18:36:59.713045Z","iopub.status.idle":"2025-07-01T18:36:59.717136Z","shell.execute_reply.started":"2025-07-01T18:36:59.713022Z","shell.execute_reply":"2025-07-01T18:36:59.716513Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 2, 10129408])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"with torch.no_grad():\n    sources = apply_model(model, wav)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:37:01.471059Z","iopub.execute_input":"2025-07-01T18:37:01.471304Z","iopub.status.idle":"2025-07-01T18:40:18.344102Z","shell.execute_reply.started":"2025-07-01T18:37:01.471276Z","shell.execute_reply":"2025-07-01T18:40:18.343253Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"vocals = sources[0][3]\nvocals_path = os.path.join(output_dir, \"vocals.wav\")\ntorchaudio.save(vocals_path, vocals.cpu(), sample_rate)\n\nprint(\"✅ Denoising complete. Saved vocals to:\", vocals_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:40:35.343458Z","iopub.execute_input":"2025-07-01T18:40:35.344172Z","iopub.status.idle":"2025-07-01T18:40:35.765346Z","shell.execute_reply.started":"2025-07-01T18:40:35.344146Z","shell.execute_reply":"2025-07-01T18:40:35.764716Z"}},"outputs":[{"name":"stdout","text":"✅ Denoising complete. Saved vocals to: /kaggle/working/denoised/vocals.wav\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from IPython.display import Audio\n\nAudio(vocals_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T17:32:18.076003Z","iopub.execute_input":"2025-06-27T17:32:18.076319Z","iopub.status.idle":"2025-06-27T17:32:19.003784Z","shell.execute_reply.started":"2025-06-27T17:32:18.076297Z","shell.execute_reply":"2025-06-27T17:32:19.002563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Speech to Text ","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nasr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\", return_timestamps=True)\nresult = asr(\"/kaggle/working/denoised/vocals.wav\")\nprint(result[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:40:39.639258Z","iopub.execute_input":"2025-07-01T18:40:39.639993Z","iopub.status.idle":"2025-07-01T18:41:48.673559Z","shell.execute_reply.started":"2025-07-01T18:40:39.639961Z","shell.execute_reply":"2025-07-01T18:41:48.672883Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 18:40:42.500564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751395242.722512      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751395242.785229      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2424424f243d48f8be639534d6a006f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28643534c1f446deae37fa06d77ae691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba91f897ba2142d7adca2cf675b3ce46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497eed0ae8e449a8a07ea3b4dd765987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e34ea6e153544e6991877b7549d0d1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37218f791b754861bae7aae3d5f3d174"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75c7d3cd6474e18ba64c846b7d379f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963de0e8731b4a8a921f073b16150757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c598bf413bed48799846900c32d20056"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8134025d4f4469bd09951a8276ec92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"596eea3b2da74c67a0d5e244f1bd7618"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\nDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n","output_type":"stream"},{"name":"stdout","text":" Down the block there's an antique shop and something in my head said stop so I walked in On the counter was a cardboard box and the sign said photos, 25 cents each Black and white, saw his thirties bright And two lovers slapping on the board to their first house The kind of love that you only find once in a lifetime The kind you don't put down And that's when I called you and it's so hard to explain But in those photos I saw us instead And somehow I know that you and I would've found each other In another life, you still would've turned my head Even if we'd been on a crowded street in 1944 And you were headed off to fight in the war You still would've been mine, we would've been timeless I would've read your love letters every single night And prayed to God you'd be coming home alright And you would've been fine, we would've been timeless Cause I believe that we were supposed to find this So even in a different life, you still would've been mine We would've been timeless I had to smile when it caught my eye There was one of a teenage couple in the driveway Holding hands on the way to a dance And the date on the back said 1958 Which brought me back to the first time I saw you Time stood still like something in this old shop I thought about it as I started looking round at these precious things that time forgot That's when I came upon a book covered in cobwebs Story of a romance torn apart by fate Hundreds of years ago they fell in love like we did And I'd die for you in the same way If I first saw your face in the 1500s off in a foreign land And I was forced to marry another man You still would've been mine, we would've been done this I would've read your love letters every single night And run away and left it all behind You still would've been mine, we would've been timeless Cause I believe that we were supposed to find this So even in a different life, you still would've been mine We would've been timeless\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"transcription = result[\"text\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transcript = result['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:41:58.196670Z","iopub.execute_input":"2025-07-01T18:41:58.197819Z","iopub.status.idle":"2025-07-01T18:41:58.201960Z","shell.execute_reply.started":"2025-07-01T18:41:58.197793Z","shell.execute_reply":"2025-07-01T18:41:58.200842Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Summarization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PegasusTokenizer, PegasusForConditionalGeneration\nfrom textwrap import wrap\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:42:01.098820Z","iopub.execute_input":"2025-07-01T18:42:01.099127Z","iopub.status.idle":"2025-07-01T18:42:01.141796Z","shell.execute_reply.started":"2025-07-01T18:42:01.099104Z","shell.execute_reply":"2025-07-01T18:42:01.141060Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Load mT5 model\nmt5_model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\nmt5_tokenizer = AutoTokenizer.from_pretrained(mt5_model_name)\nmt5_model = AutoModelForSeq2SeqLM.from_pretrained(mt5_model_name)\n\n# Load Pegasus model\npegasus_model_name = \"google/pegasus-multi_news\"\npegasus_tokenizer = PegasusTokenizer.from_pretrained(pegasus_model_name)\npegasus_model = PegasusForConditionalGeneration.from_pretrained(pegasus_model_name)\n\n#gpu or cpu\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmt5_model.to(device)\npegasus_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:42:04.955490Z","iopub.execute_input":"2025-07-01T18:42:04.955776Z","iopub.status.idle":"2025-07-01T18:43:09.591424Z","shell.execute_reply.started":"2025-07-01T18:42:04.955754Z","shell.execute_reply":"2025-07-01T18:43:09.590797Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b8ba3af661a42cdae630c8ce5c9a576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcd8a3235254a80a852b7d4069fc1ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd7f084b40614d1492c0a213e996295b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5964fd29d6ba495ba5398b455765d718"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd82487aa9047b1befc2cf6742d2b6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01c4d3d962149bbb92622e2ca1314fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99dd1dc43361409f9c3248879576ae46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"254154727b274546bb6d29e0ae447d0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"727b9fac1725455c8cd78e5e48972930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96402c47a16e45b3a0e1d9a55ef31829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6efca204c71c4a40bbaac9be577f7b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb4d8a63d2234396881c081e18e37b2e"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-multi_news and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865e323e04bf4a459df787033121e6ac"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"PegasusForConditionalGeneration(\n  (model): PegasusModel(\n    (shared): Embedding(96103, 1024, padding_idx=0)\n    (encoder): PegasusEncoder(\n      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n      (layers): ModuleList(\n        (0-15): 16 x PegasusEncoderLayer(\n          (self_attn): PegasusAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): PegasusDecoder(\n      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n      (layers): ModuleList(\n        (0-15): 16 x PegasusDecoderLayer(\n          (self_attn): PegasusAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): PegasusAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def chunk_transcript(transcript, max_chunk_chars=1000):\n    return wrap(transcript, width=max_chunk_chars, break_long_words=False)\n\ndef summarize_with_mt5(text):\n    input_ids = mt5_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).input_ids.to(device)\n    summary_ids = mt5_model.generate(input_ids, max_length=80, num_beams=4)\n    return mt5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\ndef summarize_all_chunks(chunks):\n    chunk_summaries = []\n    for i, chunk in enumerate(chunks):\n        print(f\"Summarizing chunk {i+1}/{len(chunks)}...\")\n        chunk_summary = summarize_with_mt5(chunk)\n        chunk_summaries.append(chunk_summary)\n    return \" \".join(chunk_summaries)\n\ndef summarize_with_pegasus(text):\n    inputs = pegasus_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids.to(device)\n    summary_ids = pegasus_model.generate(inputs, max_length=150, num_beams=4)\n    return pegasus_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\ndef full_summary_pipeline(transcript):\n    chunks = chunk_transcript(transcript)\n    print(f\"\\n Total Chunks: {len(chunks)}\")\n    combined_chunk_summary = summarize_all_chunks(chunks)\n    print(\"\\n Intermediate Summary:\\n\", combined_chunk_summary)\n    \n    print(\"\\n Generating Final Summary using PEGASUS...\")\n    final_summary = summarize_with_pegasus(combined_chunk_summary)\n    return final_summary\n\nfinal_summary = full_summary_pipeline(transcript)\nprint(\"\\n✅ Final Summary:\\n\", final_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:43:40.567316Z","iopub.execute_input":"2025-07-01T18:43:40.567571Z","iopub.status.idle":"2025-07-01T18:43:45.152302Z","shell.execute_reply.started":"2025-07-01T18:43:40.567554Z","shell.execute_reply":"2025-07-01T18:43:45.151522Z"}},"outputs":[{"name":"stdout","text":"\n Total Chunks: 2\nSummarizing chunk 1/2...\nSummarizing chunk 2/2...\n\n Intermediate Summary:\n The love story of a British couple who were killed in World War Two has been told by the BBC. When I first saw your face in the 1500s off in a foreign land, I was forced to marry another man.\n\n Generating Final Summary using PEGASUS...\n\n✅ Final Summary:\n – The story of a British couple who were killed in World War II has been told by the BBC. The love story of a British couple who were killed in World War II has been told by the BBC. \"When I first saw your face in the 1500s off in a foreign land, I was forced to marry another man,\" wrote one of them in a letter to the couple's daughter. \"When I first saw your face in the 1930s off in a foreign land, I was forced to marry another man.\"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n\n# # Load model and tokenizer\n# model_name = \"google/pegasus-large\"\n# tokenizer = PegasusTokenizer.from_pretrained(model_name)\n# pegasus = PegasusForConditionalGeneration.from_pretrained(model_name)\n\n# def summarize_text(text):\n#     inputs = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n#     summary_ids = pegasus.generate(inputs[\"input_ids\"], max_length=150, min_length=15, length_penalty=2.0, num_beams=4)\n#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n#     return summary\n\n# # Summarize transcription\n# summary = summarize_text(transcription)\n# print(\"📌 Summary:\\n\", summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import pipeline\n# import textwrap\n\n# # Load summarization pipeline\n# summarizer = pipeline(\"summarization\", model=\"google/pegasus-large\", tokenizer=\"google/pegasus-large\")\n\n# # Split long text into chunks (1000 tokens ~ 3000-3500 characters)\n# def split_into_chunks(text, max_chunk_size=3500):\n#     return textwrap.wrap(text, width=max_chunk_size, break_long_words=False)\n\n# # Assume 'transcript' contains your full Whisper output\n# chunks = split_into_chunks(transcript)\n\n# # Summarize each chunk\n# chunk_summaries = [summarizer(chunk, max_length=120, min_length=30, do_sample=False)[0][\"summary_text\"] for chunk in chunks]\n\n# # Optional: summarize all summaries into one\n# final_summary = summarizer(\" \".join(chunk_summaries), max_length=150, min_length=50, do_sample=False)[0][\"summary_text\"]\n\n# print(\"Final Summary:\\n\", final_summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}